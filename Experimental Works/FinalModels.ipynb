{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the best features that we got from boruta, rfe and based on importance of features of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list=['Page_popularity','Page_visited_no_of_times','Page_talking_about','Page_category','c1','c2','c3','c4','c5','c6','c7','c8',\n",
    "         'c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','CC1','CC2','CC3','CC4','CC5',\n",
    "         'Base_time','Post_length_char_count','Post_share_count','Post_promoted','Time_target','Sunday_post','Monday_post',\n",
    "         'Tuesday_post','Wednesday_post','Thrusday_post','Friday_post','Saturday_post','Sunday_base','Monday_base','Tuesday_base','Wednesday_base',\n",
    "         'Thrusday_base','Friday_base','Saturday_base','Target_variable']\n",
    "d1=pd.read_csv(\"Dataset/Training/Features_Variant_1.csv\")\n",
    "d1.columns=col_list\n",
    "d2=pd.read_csv(\"Dataset/Training/Features_Variant_2.csv\")\n",
    "d2.columns=col_list\n",
    "d3=pd.read_csv(\"Dataset/Training/Features_Variant_3.csv\")\n",
    "d3.columns=col_list\n",
    "d4=pd.read_csv(\"Dataset/Training/Features_Variant_4.csv\")\n",
    "d4.columns=col_list\n",
    "d5=pd.read_csv(\"Dataset/Training/Features_Variant_5.csv\")\n",
    "d5.columns=col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(602808, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page_popularity</th>\n",
       "      <th>Page_visited_no_of_times</th>\n",
       "      <th>Page_talking_about</th>\n",
       "      <th>Page_category</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>...</th>\n",
       "      <th>Friday_post</th>\n",
       "      <th>Saturday_post</th>\n",
       "      <th>Sunday_base</th>\n",
       "      <th>Monday_base</th>\n",
       "      <th>Tuesday_base</th>\n",
       "      <th>Wednesday_base</th>\n",
       "      <th>Thrusday_base</th>\n",
       "      <th>Friday_base</th>\n",
       "      <th>Saturday_base</th>\n",
       "      <th>Target_variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page_popularity  Page_visited_no_of_times  Page_talking_about  \\\n",
       "0           634995                         0                 463   \n",
       "1           634995                         0                 463   \n",
       "2           634995                         0                 463   \n",
       "3           634995                         0                 463   \n",
       "4           634995                         0                 463   \n",
       "\n",
       "   Page_category   c1     c2         c3   c4         c5   c6       ...         \\\n",
       "0              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "1              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "2              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "3              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "4              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "\n",
       "   Friday_post  Saturday_post  Sunday_base  Monday_base  Tuesday_base  \\\n",
       "0            0              0            0            0             0   \n",
       "1            1              0            0            0             0   \n",
       "2            1              0            0            1             0   \n",
       "3            0              0            0            0             0   \n",
       "4            0              0            0            0             0   \n",
       "\n",
       "   Wednesday_base  Thrusday_base  Friday_base  Saturday_base  Target_variable  \n",
       "0               0              0            1              0                0  \n",
       "1               0              0            0              1                0  \n",
       "2               0              0            0              0                0  \n",
       "3               1              0            0              0                0  \n",
       "4               0              0            1              0                0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_main = [d1 , d2 , d3 , d4 , d5]\n",
    "df = pd.concat(frames_main)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421965, 10) , (180843, 10) , (421965,) , (180843,)\n"
     ]
    }
   ],
   "source": [
    "df_train,df_test = train_test_split(df,train_size=0.7,random_state=42)\n",
    "column_list1=['CC2','Base_time','Post_share_count','c3','c8','c18','CC1','CC4','Post_length_char_count','CC5']\n",
    "x_train=df_train[column_list1]\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test[column_list1]\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)\n",
    "print(x_train.shape,',',x_test.shape,',',y_train.shape,',',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summ=pd.DataFrame(columns=['Models','Dataset','R-sq','RMSE','MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm=linear_model.LinearRegression()\n",
    "lm.fit(x_train_sc,y_train)\n",
    "filename = 'Linear_model.sav'\n",
    "pickle.dump(lm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression  on  Training  dataset   : \n",
      "R2   : 0.332506248273\n",
      "MAE  : 8.02035734871\n",
      "RMSE : 28.1477811342\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=lm.predict(x_train_sc)\n",
    "r2=r2_score(y_train,y_train_pred)\n",
    "mae=mean_absolute_error(y_train,y_train_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "mod='Linear Regression'\n",
    "dataset='Training'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression  on  Testing  dataset   : \n",
      "R2   : 0.336745254011\n",
      "MAE  : 7.86886458127\n",
      "RMSE : 28.0847977307\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=lm.predict(x_test_sc)\n",
    "r2=r2_score(y_test,y_test_pred)\n",
    "mae=mean_absolute_error(y_test,y_test_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "mod='Linear Regression'\n",
    "dataset='Testing'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=12, n_jobs=1,\n",
    "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "rf.fit(x_train_sc, y_train)\n",
    "filename = 'RF_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest  on  Training  dataset   : \n",
      "R2   : 0.825028258434\n",
      "MAE  : 3.41683677454\n",
      "RMSE : 14.4113451761\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=rf.predict(x_train_sc)\n",
    "r2=r2_score(y_train,y_train_pred)\n",
    "mae=mean_absolute_error(y_train,y_train_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "mod='Random Forest'\n",
    "dataset='Training'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest  on  Testing  dataset   : \n",
      "R2   : 0.69751204154\n",
      "MAE  : 3.77067342141\n",
      "RMSE : 18.9664112272\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=rf.predict(x_test_sc)\n",
    "r2=r2_score(y_test,y_test_pred)\n",
    "mae=mean_absolute_error(y_test,y_test_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "mod='Random Forest'\n",
    "dataset='Testing'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(15, 15, 15), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=50, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
    "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "mlp.fit(x_train_sc,y_train)\n",
    "filename = 'NN_model.sav'\n",
    "pickle.dump(mlp, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network  on  Training  dataset   : \n",
      "R2   : 0.66841925702\n",
      "MAE  : 4.49006115772\n",
      "RMSE : 19.8387915067\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=mlp.predict(x_train_sc)\n",
    "r2=r2_score(y_train,y_train_pred)\n",
    "mae=mean_absolute_error(y_train,y_train_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "mod='Neural Network'\n",
    "dataset='Training'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network  on  Testing  dataset   : \n",
      "R2   : 0.640941868789\n",
      "MAE  : 4.53208214388\n",
      "RMSE : 20.6639575185\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=mlp.predict(x_test_sc)\n",
    "r2=r2_score(y_test,y_test_pred)\n",
    "mae=mean_absolute_error(y_test,y_test_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "mod='Neural Network'\n",
    "dataset='Testing'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "          metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
    "          weights='uniform')\n",
    "knn.fit(x_train_sc,y_train)\n",
    "filename = 'KNN_model.sav'\n",
    "pickle.dump(knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN on training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN  on  Training  dataset   : \n",
      "R2   : 0.847831482929\n",
      "MAE  : 2.00971289088\n",
      "RMSE : 13.4394955325\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=knn.predict(x_train_sc)\n",
    "r2=r2_score(y_train,y_train_pred)\n",
    "mae=mean_absolute_error(y_train,y_train_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "mod='KNN'\n",
    "dataset='Training'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN  on  Testing  dataset   : \n",
      "R2   : 0.640941868789\n",
      "MAE  : 4.53208214388\n",
      "RMSE : 20.6639575185\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=knn.predict(x_test_sc)\n",
    "r2=r2_score(y_test,y_test_pred)\n",
    "mae=mean_absolute_error(y_test,y_test_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "mod='KNN'\n",
    "dataset='Testing'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>R-sq</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.332506</td>\n",
       "      <td>28.147781</td>\n",
       "      <td>8.020357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.336745</td>\n",
       "      <td>28.084798</td>\n",
       "      <td>7.868865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.825028</td>\n",
       "      <td>14.411345</td>\n",
       "      <td>3.416837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.697512</td>\n",
       "      <td>18.966411</td>\n",
       "      <td>3.770673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.668419</td>\n",
       "      <td>19.838792</td>\n",
       "      <td>4.490061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.640942</td>\n",
       "      <td>20.663958</td>\n",
       "      <td>4.532082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.847831</td>\n",
       "      <td>13.439496</td>\n",
       "      <td>2.009713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.640942</td>\n",
       "      <td>20.663958</td>\n",
       "      <td>4.532082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Models   Dataset      R-sq       RMSE       MAE\n",
       "0  Linear Regression  Training  0.332506  28.147781  8.020357\n",
       "1  Linear Regression   Testing  0.336745  28.084798  7.868865\n",
       "2      Random Forest  Training  0.825028  14.411345  3.416837\n",
       "3      Random Forest   Testing  0.697512  18.966411  3.770673\n",
       "4     Neural Network  Training  0.668419  19.838792  4.490061\n",
       "5     Neural Network   Testing  0.640942  20.663958  4.532082\n",
       "6                KNN  Training  0.847831  13.439496  2.009713\n",
       "7                KNN   Testing  0.640942  20.663958  4.532082"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "svr.fit(x_train_sc,y_train)\n",
    "filename = 'SVR_model.sav'\n",
    "pickle.dump(svr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred=svr.predict(x_train_sc)\n",
    "r2=r2_score(y_train,y_train_pred)\n",
    "mae=mean_absolute_error(y_train,y_train_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_train,y_train_pred))\n",
    "mod='SVR'\n",
    "dataset='Training'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred=svr.predict(x_test_sc)\n",
    "r2=r2_score(y_test,y_test_pred)\n",
    "mae=mean_absolute_error(y_test,y_test_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "mod='SVR'\n",
    "dataset='Testing'\n",
    "print(mod,' on ',dataset,' dataset ',' : ')\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "data={'Models':mod,'Dataset':dataset,'R-sq':r2,'RMSE':rmse,'MAE':mae}\n",
    "df_summ=df_summ.append(data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summ.to_csv('Summarry.csv',sep=',',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
