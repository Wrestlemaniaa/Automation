{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def mean_absolute_percentage_error(y_true, y_pred): \n",
    "#         y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "#         return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list=['Page_popularity','Page_visited_no_of_times','Page_talking_about','Page_category','c1','c2','c3','c4','c5','c6','c7','c8',\n",
    "         'c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','CC1','CC2','CC3','CC4','CC5',\n",
    "         'Base_time','Post_length_char_count','Post_share_count','Post_promoted','Time_target','Sunday_post','Monday_post',\n",
    "         'Tuesday_post','Wednesday_post','Thrusday_post','Friday_post','Saturday_post','Sunday_base','Monday_base','Tuesday_base','Wednesday_base',\n",
    "         'Thrusday_base','Friday_base','Saturday_base','Target_variable']\n",
    "d1=pd.read_csv(\"Dataset/Training/Features_Variant_1.csv\")\n",
    "d1.columns=col_list\n",
    "d2=pd.read_csv(\"Dataset/Training/Features_Variant_2.csv\")\n",
    "d2.columns=col_list\n",
    "d3=pd.read_csv(\"Dataset/Training/Features_Variant_3.csv\")\n",
    "d3.columns=col_list\n",
    "d4=pd.read_csv(\"Dataset/Training/Features_Variant_4.csv\")\n",
    "d4.columns=col_list\n",
    "d5=pd.read_csv(\"Dataset/Training/Features_Variant_5.csv\")\n",
    "d5.columns=col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page_popularity</th>\n",
       "      <th>Page_visited_no_of_times</th>\n",
       "      <th>Page_talking_about</th>\n",
       "      <th>Page_category</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>...</th>\n",
       "      <th>Friday_post</th>\n",
       "      <th>Saturday_post</th>\n",
       "      <th>Sunday_base</th>\n",
       "      <th>Monday_base</th>\n",
       "      <th>Tuesday_base</th>\n",
       "      <th>Wednesday_base</th>\n",
       "      <th>Thrusday_base</th>\n",
       "      <th>Friday_base</th>\n",
       "      <th>Saturday_base</th>\n",
       "      <th>Target_variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>13.158779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.99364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>13.158779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.99364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>13.158779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.99364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>13.158779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.99364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>13.158779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.99364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page_popularity  Page_visited_no_of_times  Page_talking_about  \\\n",
       "0           634995                         0                 463   \n",
       "1           634995                         0                 463   \n",
       "2           634995                         0                 463   \n",
       "3           634995                         0                 463   \n",
       "4           634995                         0                 463   \n",
       "\n",
       "   Page_category   c1      c2         c3   c4        c5   c6       ...         \\\n",
       "0              1  0.0  1280.0  13.158779  1.0  94.99364  0.0       ...          \n",
       "1              1  0.0  1280.0  13.158779  1.0  94.99364  0.0       ...          \n",
       "2              1  0.0  1280.0  13.158779  1.0  94.99364  0.0       ...          \n",
       "3              1  0.0  1280.0  13.158779  1.0  94.99364  0.0       ...          \n",
       "4              1  0.0  1280.0  13.158779  1.0  94.99364  0.0       ...          \n",
       "\n",
       "   Friday_post  Saturday_post  Sunday_base  Monday_base  Tuesday_base  \\\n",
       "0            0              0            1            0             0   \n",
       "1            1              0            0            0             0   \n",
       "2            1              0            0            1             0   \n",
       "3            0              0            0            0             0   \n",
       "4            0              0            0            0             0   \n",
       "\n",
       "   Wednesday_base  Thrusday_base  Friday_base  Saturday_base  Target_variable  \n",
       "0               0              0            0              0                0  \n",
       "1               0              0            0              1                0  \n",
       "2               0              0            0              0                0  \n",
       "3               0              1            0              0                0  \n",
       "4               1              0            0              0                0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_main = [d1 , d2 , d3 , d4 , d5]\n",
    "df = pd.concat(frames_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602808, 54)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page_popularity</th>\n",
       "      <th>Page_visited_no_of_times</th>\n",
       "      <th>Page_talking_about</th>\n",
       "      <th>Page_category</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>...</th>\n",
       "      <th>Friday_post</th>\n",
       "      <th>Saturday_post</th>\n",
       "      <th>Sunday_base</th>\n",
       "      <th>Monday_base</th>\n",
       "      <th>Tuesday_base</th>\n",
       "      <th>Wednesday_base</th>\n",
       "      <th>Thrusday_base</th>\n",
       "      <th>Friday_base</th>\n",
       "      <th>Saturday_base</th>\n",
       "      <th>Target_variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>634995</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>11.291045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.495138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page_popularity  Page_visited_no_of_times  Page_talking_about  \\\n",
       "0           634995                         0                 463   \n",
       "1           634995                         0                 463   \n",
       "2           634995                         0                 463   \n",
       "3           634995                         0                 463   \n",
       "4           634995                         0                 463   \n",
       "\n",
       "   Page_category   c1     c2         c3   c4         c5   c6       ...         \\\n",
       "0              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "1              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "2              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "3              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "4              1  0.0  806.0  11.291045  1.0  70.495138  0.0       ...          \n",
       "\n",
       "   Friday_post  Saturday_post  Sunday_base  Monday_base  Tuesday_base  \\\n",
       "0            0              0            0            0             0   \n",
       "1            1              0            0            0             0   \n",
       "2            1              0            0            1             0   \n",
       "3            0              0            0            0             0   \n",
       "4            0              0            0            0             0   \n",
       "\n",
       "   Wednesday_base  Thrusday_base  Friday_base  Saturday_base  Target_variable  \n",
       "0               0              0            1              0                0  \n",
       "1               0              0            0              1                0  \n",
       "2               0              0            0              0                0  \n",
       "3               1              0            0              0                0  \n",
       "4               0              0            1              0                0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df=df[(df['Page_popularity']-df['Page_popularity'].mean()).abs() <= 3*df['Page_popularity'].std()]\n",
    "# df=df[(df['Page_visited_no_of_times']-df['Page_visited_no_of_times'].mean()).abs() <= 3*df['Page_visited_no_of_times'].std()]\n",
    "# df=df[(df['Page_talking_about']-df['Page_talking_about'].mean()).abs() <= 3*df['Page_talking_about'].std()]\n",
    "# df=df[(df['Page_category']-df['Page_category'].mean()).abs() <= 3*df['Page_category'].std()]\n",
    "# df=df[(df['c1']-df['c1'].mean()).abs() <= 3*df['c1'].std()]\n",
    "# df=df[(df['c2']-df['c2'].mean()).abs() <= 3*df['c2'].std()]\n",
    "# df=df[(df['c3']-df['c3'].mean()).abs() <= 3*df['c3'].std()]\n",
    "# df=df[(df['c4']-df['c4'].mean()).abs() <= 3*df['c4'].std()]\n",
    "# df=df[(df['c5']-df['c5'].mean()).abs() <= 3*df['c5'].std()]\n",
    "# df=df[(df['c6']-df['c6'].mean()).abs() <= 3*df['c6'].std()]\n",
    "# df=df[(df['c7']-df['c7'].mean()).abs() <= 3*df['c7'].std()]\n",
    "# df=df[(df['c8']-df['c8'].mean()).abs() <= 3*df['c8'].std()]\n",
    "# df=df[(df['c9']-df['c9'].mean()).abs() <= 3*df['c9'].std()]\n",
    "# df=df[(df['c10']-df['c10'].mean()).abs() <= 3*df['c10'].std()]\n",
    "# df=df[(df['c11']-df['c11'].mean()).abs() <= 3*df['c11'].std()]\n",
    "# df=df[(df['c12']-df['c12'].mean()).abs() <= 3*df['c12'].std()]\n",
    "# df=df[(df['c13']-df['c13'].mean()).abs() <= 3*df['c13'].std()]\n",
    "# df=df[(df['c14']-df['c14'].mean()).abs() <= 3*df['c14'].std()]\n",
    "# df=df[(df['c15']-df['c15'].mean()).abs() <= 3*df['c15'].std()]\n",
    "# df=df[(df['c16']-df['c16'].mean()).abs() <= 3*df['c16'].std()]\n",
    "# df=df[(df['c17']-df['c17'].mean()).abs() <= 3*df['c17'].std()]\n",
    "# df=df[(df['c18']-df['c18'].mean()).abs() <= 3*df['c18'].std()]\n",
    "# df=df[(df['c19']-df['c19'].mean()).abs() <= 3*df['c19'].std()]\n",
    "# df=df[(df['c20']-df['c20'].mean()).abs() <= 3*df['c20'].std()]\n",
    "# df=df[(df['c21']-df['c21'].mean()).abs() <= 3*df['c21'].std()]\n",
    "# df=df[(df['c22']-df['c22'].mean()).abs() <= 3*df['c22'].std()]\n",
    "# df=df[(df['c23']-df['c23'].mean()).abs() <= 3*df['c23'].std()]\n",
    "# df=df[(df['c24']-df['c24'].mean()).abs() <= 3*df['c24'].std()]\n",
    "# df=df[(df['c25']-df['c25'].mean()).abs() <= 3*df['c25'].std()]\n",
    "# df=df[(df['CC1']-df['CC1'].mean()).abs() <= 3*df['CC1'].std()]\n",
    "# df=df[(df['CC2']-df['CC2'].mean()).abs() <= 3*df['CC2'].std()]\n",
    "# df=df[(df['CC3']-df['CC3'].mean()).abs() <= 3*df['CC3'].std()]\n",
    "# df=df[(df['CC4']-df['CC4'].mean()).abs() <= 3*df['CC4'].std()]\n",
    "# df=df[(df['CC5']-df['CC5'].mean()).abs() <= 3*df['CC5'].std()]\n",
    "# df=df[(df['Base_time_something']-df['Base_time_something'].mean()).abs() <= 3*df['Base_time_something'].std()]\n",
    "# df=df[(df['Post_length_char_count']-df['Post_length_char_count'].mean()).abs() <= 3*df['Post_length_char_count'].std()]\n",
    "# df=df[(df['Post_share_count']-df['Post_share_count'].mean()).abs() <= 3*df['Post_share_count'].std()]\n",
    "# df=df[(df['Post_promoted']-df['Post_promoted'].mean()).abs() <= 3*df['Post_promoted'].std()]\n",
    "# df=df[(df['Time_target']-df['Time_target'].mean()).abs() <= 3*df['Time_target'].std()]\n",
    "# df=df[(df['Sunday_post']-df['Sunday_post'].mean()).abs() <= 3*df['Sunday_post'].std()]\n",
    "# df=df[(df['Monday_post']-df['Monday_post'].mean()).abs() <= 3*df['Monday_post'].std()]\n",
    "# df=df[(df['Tuesday_post']-df['Tuesday_post'].mean()).abs() <= 3*df['Tuesday_post'].std()]\n",
    "# df=df[(df['Wednesday_post']-df['Wednesday_post'].mean()).abs() <= 3*df['Wednesday_post'].std()]\n",
    "# df=df[(df['Thrusday_post']-df['Thrusday_post'].mean()).abs() <= 3*df['Thrusday_post'].std()]\n",
    "# df=df[(df['Friday_post']-df['Friday_post'].mean()).abs() <= 3*df['Friday_post'].std()]\n",
    "# df=df[(df['Saturday_post']-df['Saturday_post'].mean()).abs() <= 3*df['Saturday_post'].std()]\n",
    "# df=df[(df['Sunday_base']-df['Sunday_base'].mean()).abs() <= 3*df['Sunday_base'].std()]\n",
    "# df=df[(df['Monday_base']-df['Monday_base'].mean()).abs() <= 3*df['Monday_base'].std()]\n",
    "# df=df[(df['Tuesday_base']-df['Tuesday_base'].mean()).abs() <= 3*df['Tuesday_base'].std()]\n",
    "# df=df[(df['Wednesday_base']-df['Wednesday_base'].mean()).abs() <= 3*df['Wednesday_base'].std()]\n",
    "# df=df[(df['Thrusday_base']-df['Thrusday_base'].mean()).abs() <= 3*df['Thrusday_base'].std()]\n",
    "# df=df[(df['Friday_base']-df['Friday_base'].mean()).abs() <= 3*df['Friday_base'].std()]\n",
    "# df=df[(df['Saturday_base']-df['Saturday_base'].mean()).abs() <= 3*df['Saturday_base'].std()]\n",
    "# df=df[(df['Target_variable']-df['Target_variable'].mean()).abs() <= 3*df['Target_variable'].std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(602808, 54)\n"
     ]
    }
   ],
   "source": [
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,train_size=0.7,random_state=42)\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.948725694909\n",
      "MAE  : 1.37498332069\n",
      "RMSE : 7.8013624336\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=rf.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.680262095601\n",
      "MAE  : 3.70047647041\n",
      "RMSE : 19.4997112021\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=rf.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of features for Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: CC2                  Importance: 0.28\n",
      "Variable: Base_time_something  Importance: 0.21\n",
      "Variable: Post_share_count     Importance: 0.12\n",
      "Variable: c3                   Importance: 0.04\n",
      "Variable: CC4                  Importance: 0.03\n",
      "Variable: CC5                  Importance: 0.03\n",
      "Variable: Page_talking_about   Importance: 0.02\n",
      "Variable: c10                  Importance: 0.02\n",
      "Variable: c13                  Importance: 0.02\n",
      "Variable: c15                  Importance: 0.02\n",
      "Variable: c25                  Importance: 0.02\n",
      "Variable: CC1                  Importance: 0.02\n",
      "Variable: c2                   Importance: 0.01\n",
      "Variable: c4                   Importance: 0.01\n",
      "Variable: c5                   Importance: 0.01\n",
      "Variable: c8                   Importance: 0.01\n",
      "Variable: c9                   Importance: 0.01\n",
      "Variable: c12                  Importance: 0.01\n",
      "Variable: c14                  Importance: 0.01\n",
      "Variable: c17                  Importance: 0.01\n",
      "Variable: c18                  Importance: 0.01\n",
      "Variable: c19                  Importance: 0.01\n",
      "Variable: c20                  Importance: 0.01\n",
      "Variable: c21                  Importance: 0.01\n",
      "Variable: c22                  Importance: 0.01\n",
      "Variable: c23                  Importance: 0.01\n",
      "Variable: c24                  Importance: 0.01\n",
      "Variable: Tuesday_post         Importance: 0.01\n",
      "Variable: c1                   Importance: 0.0\n",
      "Variable: c6                   Importance: 0.0\n",
      "Variable: c11                  Importance: 0.0\n",
      "Variable: c16                  Importance: 0.0\n",
      "Variable: CC3                  Importance: 0.0\n",
      "Variable: Time_target          Importance: 0.0\n",
      "Variable: Wednesday_post       Importance: 0.0\n",
      "Variable: Thrusday_base        Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(x_train.columns)\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(x_train, round(importance, 2)) for x_train, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm=linear_model.LinearRegression()\n",
    "Linear_mod=lm.fit(x_train_sc,y_train)\n",
    "Linear_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.335389727511\n",
      "MAE  : 8.05969906559\n",
      "RMSE : 28.0869181029\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=lm.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.337190386786\n",
      "MAE  : 7.91397172092\n",
      "RMSE : 28.0753718183\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=lm.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important features based on coefficients of linear model. By droping least singnificant feature our model can give better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: c18                  Importance: 90.95\n",
      "Variable: c3                   Importance: 90.64\n",
      "Variable: c20                  Importance: 11.7\n",
      "Variable: c5                   Importance: 11.54\n",
      "Variable: CC2                  Importance: 10.88\n",
      "Variable: c4                   Importance: 8.46\n",
      "Variable: c19                  Importance: 6.81\n",
      "Variable: CC5                  Importance: 6.26\n",
      "Variable: c25                  Importance: 5.97\n",
      "Variable: c1                   Importance: 5.42\n",
      "Variable: c10                  Importance: 4.63\n",
      "Variable: c16                  Importance: 4.45\n",
      "Variable: Base_time_something  Importance: 3.97\n",
      "Variable: c2                   Importance: 3.92\n",
      "Variable: c13                  Importance: 3.78\n",
      "Variable: c8                   Importance: 3.57\n",
      "Variable: CC3                  Importance: 3.16\n",
      "Variable: CC1                  Importance: 2.61\n",
      "Variable: c17                  Importance: 2.42\n",
      "Variable: c9                   Importance: 2.37\n",
      "Variable: Post_share_count     Importance: 2.23\n",
      "Variable: c14                  Importance: 1.3\n",
      "Variable: Page_talking_about   Importance: 1.19\n",
      "Variable: c15                  Importance: 1.08\n",
      "Variable: c21                  Importance: 0.88\n",
      "Variable: c23                  Importance: 0.85\n",
      "Variable: Time_target          Importance: 0.85\n",
      "Variable: c24                  Importance: 0.59\n",
      "Variable: c22                  Importance: 0.5\n",
      "Variable: CC4                  Importance: 0.43\n",
      "Variable: c6                   Importance: 0.35\n",
      "Variable: Thrusday_base        Importance: 0.34\n",
      "Variable: Wednesday_post       Importance: 0.3\n",
      "Variable: c12                  Importance: 0.2\n",
      "Variable: Wednesday_base       Importance: 0.18\n",
      "Variable: Saturday_post        Importance: 0.17\n",
      "Variable: c11                  Importance: 0.16\n",
      "Variable: Sunday_post          Importance: 0.16\n",
      "Variable: Tuesday_post         Importance: 0.16\n",
      "Variable: Monday_base          Importance: 0.16\n",
      "Variable: Tuesday_base         Importance: 0.16\n",
      "Variable: Monday_post          Importance: 0.15\n",
      "Variable: c7                   Importance: 0.14\n",
      "Variable: Friday_base          Importance: 0.14\n",
      "Variable: Saturday_base        Importance: 0.08\n",
      "Variable: Sunday_base          Importance: 0.07\n",
      "Variable: Page_visited_no_of_times Importance: 0.05\n",
      "Variable: Page_category        Importance: 0.02\n",
      "Variable: Friday_post          Importance: 0.02\n",
      "Variable: Post_length_char_count Importance: 0.01\n",
      "Variable: Thrusday_post        Importance: 0.01\n",
      "Variable: Post_promoted        Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_importances = [(x_train, abs((round(lm.coef_, 2)))) for x_train, lm.coef_ in zip(x_train.columns, lm.coef_)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Linear Regression Model by droping least singnificant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_col_list=['Post_promoted','Thrusday_post','Post_length_char_count','Friday_post','Page_category','Page_visited_no_of_times',\n",
    "              'Sunday_base','Saturday_base','Friday_base','Saturday_post','Sunday_post','Monday_post','Tuesday_base','Monday_base'\n",
    "               ,'Wednesday_base','c7']\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "x_train.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "x_test.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm=linear_model.LinearRegression()\n",
    "Linear_mod=lm.fit(x_train_sc,y_train)\n",
    "Linear_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.335327755411\n",
      "MAE  : 8.06058162092\n",
      "RMSE : 28.0882275656\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=lm.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.337124231996\n",
      "MAE  : 7.91511394928\n",
      "RMSE : 28.0767728798\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=lm.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important features based on coefficients of linear model. By droping least singnificant feature our model can give better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: c18                  Importance: 91.06\n",
      "Variable: c3                   Importance: 90.59\n",
      "Variable: c20                  Importance: 11.74\n",
      "Variable: c5                   Importance: 11.53\n",
      "Variable: CC2                  Importance: 10.88\n",
      "Variable: c4                   Importance: 8.43\n",
      "Variable: c19                  Importance: 6.8\n",
      "Variable: CC5                  Importance: 6.26\n",
      "Variable: c25                  Importance: 6.06\n",
      "Variable: c1                   Importance: 5.38\n",
      "Variable: c10                  Importance: 4.67\n",
      "Variable: c16                  Importance: 4.42\n",
      "Variable: Base_time_something  Importance: 3.97\n",
      "Variable: c2                   Importance: 3.91\n",
      "Variable: c13                  Importance: 3.84\n",
      "Variable: c8                   Importance: 3.63\n",
      "Variable: CC3                  Importance: 3.16\n",
      "Variable: CC1                  Importance: 2.61\n",
      "Variable: c17                  Importance: 2.44\n",
      "Variable: c9                   Importance: 2.37\n",
      "Variable: Post_share_count     Importance: 2.22\n",
      "Variable: c14                  Importance: 1.31\n",
      "Variable: Page_talking_about   Importance: 1.19\n",
      "Variable: c15                  Importance: 1.16\n",
      "Variable: c21                  Importance: 0.95\n",
      "Variable: Time_target          Importance: 0.87\n",
      "Variable: c23                  Importance: 0.85\n",
      "Variable: c22                  Importance: 0.64\n",
      "Variable: c24                  Importance: 0.59\n",
      "Variable: CC4                  Importance: 0.44\n",
      "Variable: Thrusday_base        Importance: 0.37\n",
      "Variable: c6                   Importance: 0.34\n",
      "Variable: Wednesday_post       Importance: 0.32\n",
      "Variable: c12                  Importance: 0.28\n",
      "Variable: Tuesday_post         Importance: 0.26\n",
      "Variable: c11                  Importance: 0.16\n"
     ]
    }
   ],
   "source": [
    "feature_importances = [(x_train, abs((round(lm.coef_, 2)))) for x_train, lm.coef_ in zip(x_train.columns, lm.coef_)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Random Forest Model by droping least singnificant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_list=['Saturday_base','Friday_base','Thrusday_base','Wednesday_base','Tuesday_base','Monday_base','Sunday_base','Saturday_post',\n",
    "              'Friday_post','Thrusday_post','Wednesday_post','Tuesday_post','Monday_post','Sunday_post','Post_promoted','CC3',\n",
    "              'c22','c16','c11','c6','c1'\n",
    "               ,'c25','c24','c23','c21','c20','c19','c18','c17','c14','c12','c10','c9','c8','c7','c5','c4','Page_category',\n",
    "              'Page_visited_no_of_times'\n",
    "              ,'CC5','CC4']\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "x_train.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "x_test.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor(max_features='sqrt',random_state=42,n_estimators=20)\n",
    "rf.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.948621333664\n",
      "MAE  : 1.32070562649\n",
      "RMSE : 7.80929765607\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=rf.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "# R2   : 0.950056023315\n",
    "# MAE  : 1.32380559209\n",
    "# RMSE : 7.69949289765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.693571943863\n",
      "MAE  : 3.62707040282\n",
      "RMSE : 19.0895363516\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=rf.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "# R2   : 0.689338428435\n",
    "# MAE  : 3.59382675396\n",
    "# RMSE : 19.2209515812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of features for Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Base_time_something  Importance: 0.25\n",
      "Variable: CC2                  Importance: 0.23\n",
      "Variable: Post_share_count     Importance: 0.11\n",
      "Variable: c3                   Importance: 0.09\n",
      "Variable: CC1                  Importance: 0.09\n",
      "Variable: c13                  Importance: 0.05\n",
      "Variable: c15                  Importance: 0.05\n",
      "Variable: Post_length_char_count Importance: 0.05\n",
      "Variable: c2                   Importance: 0.04\n",
      "Variable: Page_talking_about   Importance: 0.03\n",
      "Variable: Time_target          Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(x_train.columns)\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(x_train, round(importance, 2)) for x_train, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,train_size=0.7,random_state=42)\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15, 15, 15), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=50, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(15,15,15),max_iter=50,alpha=1.00000000e-06,random_state=42)\n",
    "mlp.fit(x_train_sc,y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.685184833616\n",
      "MAE  : 4.36964900448\n",
      "RMSE : 19.3307358523\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=mlp.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.636827679586\n",
      "MAE  : 4.46539761424\n",
      "RMSE : 20.7820070434\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=mlp.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Random Forest Model by droping least singnificant features obtained from random grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_col_list=['Saturday_base','Friday_base','Thrusday_base','Wednesday_base','Tuesday_base','Monday_base','Sunday_base','Saturday_post',\n",
    "              'Friday_post','Thrusday_post','Wednesday_post','Tuesday_post','Monday_post','Sunday_post','Post_promoted','CC3',\n",
    "              'c16','c11','c6','c1'\n",
    "               ,'c24','c23','c22','c21','c20','c17','c15','c14','c12','c10','c7','c5','c2','Page_category','Page_talking_about',\n",
    "               'Page_visited_no_of_times','c25','c19','c13','c9','c4','Time_target']\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "x_train.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "x_test.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model After using tuned  hyperparameters which we got using random grid search and experimenting with its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=12, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=12, n_jobs=1,\n",
    "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "rf.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.825524258155\n",
      "MAE  : 3.41525196523\n",
      "RMSE : 14.390904458\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=rf.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest on Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.701754183555\n",
      "MAE  : 3.75759607945\n",
      "RMSE : 18.832947575\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=rf.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of features for Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: CC2                  Importance: 0.34\n",
      "Variable: Base_time_something  Importance: 0.25\n",
      "Variable: Post_share_count     Importance: 0.13\n",
      "Variable: c3                   Importance: 0.08\n",
      "Variable: c8                   Importance: 0.05\n",
      "Variable: c18                  Importance: 0.04\n",
      "Variable: CC1                  Importance: 0.03\n",
      "Variable: CC4                  Importance: 0.03\n",
      "Variable: Post_length_char_count Importance: 0.03\n",
      "Variable: CC5                  Importance: 0.02\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(x_train.columns)\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(x_train, round(importance, 2)) for x_train, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking linear Regression with features used for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_col_list=['Saturday_base','Friday_base','Thrusday_base','Wednesday_base','Tuesday_base','Monday_base','Sunday_base','Saturday_post',\n",
    "              'Friday_post','Thrusday_post','Wednesday_post','Tuesday_post','Monday_post','Sunday_post','Post_promoted','CC3',\n",
    "              'c16','c11','c6','c1'\n",
    "               ,'c24','c23','c22','c21','c20','c17','c15','c14','c12','c10','c7','c5','c2','Page_category','Page_talking_about',\n",
    "               'Page_visited_no_of_times','c25','c19','c13','c9','c4','Time_target']\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "x_train.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "x_test.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm=linear_model.LinearRegression()\n",
    "Linear_mod=lm.fit(x_train_sc,y_train)\n",
    "Linear_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.332506248273\n",
      "MAE  : 8.02035734871\n",
      "RMSE : 28.1477811342\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=lm.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.336745254011\n",
      "MAE  : 7.86886458127\n",
      "RMSE : 28.0847977307\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=lm.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: c18                  Importance: 68.48\n",
      "Variable: c3                   Importance: 67.95\n",
      "Variable: CC2                  Importance: 14.26\n",
      "Variable: c8                   Importance: 7.18\n",
      "Variable: Base_time_something  Importance: 3.99\n",
      "Variable: CC1                  Importance: 2.6\n",
      "Variable: CC5                  Importance: 2.13\n",
      "Variable: Post_share_count     Importance: 1.73\n",
      "Variable: CC4                  Importance: 0.43\n",
      "Variable: Post_length_char_count Importance: 0.02\n"
     ]
    }
   ],
   "source": [
    "feature_importances = [(x_train, abs((round(lm.coef_, 2)))) for x_train, lm.coef_ in zip(x_train.columns, lm.coef_)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking neural networks with features selected by random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_col_list=['Saturday_base','Friday_base','Thrusday_base','Wednesday_base','Tuesday_base','Monday_base','Sunday_base','Saturday_post',\n",
    "              'Friday_post','Thrusday_post','Wednesday_post','Tuesday_post','Monday_post','Sunday_post','Post_promoted','CC3',\n",
    "              'c16','c11','c6','c1'\n",
    "               ,'c24','c23','c22','c21','c20','c17','c15','c14','c12','c10','c7','c5','c2','Page_category','Page_talking_about',\n",
    "               'Page_visited_no_of_times','c25','c19','c13','c9','c4','Time_target']\n",
    "x_train=df_train.iloc[:,1:53]\n",
    "x_train.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_train=df_train['Target_variable']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:53]\n",
    "x_test.drop(drop_col_list,axis=1,inplace=True)\n",
    "y_test=df_test['Target_variable']\n",
    "scaler.fit(x_test)\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1e-06, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15, 15, 15), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=50, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(15,15,15),max_iter=50,alpha=1.00000000e-06,random_state=42)\n",
    "mlp.fit(x_train_sc,y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.649385555058\n",
      "MAE  : 4.31180315669\n",
      "RMSE : 20.4002488624\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=mlp.predict(x_train_sc)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.625955467682\n",
      "MAE  : 4.32644421213\n",
      "RMSE : 21.0907863648\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=mlp.predict(x_test_sc)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
